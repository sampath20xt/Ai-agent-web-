Using AI Agents for Web Scraping Instead of Traditional Automation

Since your ultimate goal is to use AI agents, we need to shift from rule-based automation (e.g., Selenium, Playwright) to autonomous AI-driven web scraping agents.

ğŸš€ AI Agent-Based Web Scraping Approach

Instead of manually defining each step (searching, clicking, extracting, summarizing, screenshotting), we will:
	1.	Use an AI agent to plan actions dynamically (e.g., searching, extracting).
	2.	Let the AI decide what steps to take in real-time.
	3.	Use Reinforcement Learning (RAG) + LLMs to improve web interactions.

ğŸ”¹ Best AI Agent Frameworks for Web Scraping

AI Agent Framework	Key Features	Best For
Auto-GPT	Fully autonomous LLM agent, executes multi-step plans	General web research
BabyAGI	AI-powered reasoning with a memory module	Long-term data extraction
LangChain Agents	LLM-powered actions + integrations (APIs, browsers)	AI-driven structured scraping
SuperAGI	Advanced multi-agent system for automation	Continuous agent-based browsing

ğŸ› ï¸ Implementing AI Agent-Based Web Scraping

Hereâ€™s an AI-based web scraping pipeline using LangChain AI Agents. It replaces traditional automation with an AI-driven decision-making system.

ğŸš€ AI Agent-Based Web Scraper (Using LangChain)

âœ… What this code does:
	1.	Uses AI Agents (LangChain) to decide search actions.
	2.	Performs Google search autonomously.
	3.	Extracts text dynamically without manual clicking.
	4.	Summarizes results using Gemini 1.5 Pro.
	5.	Captures a screenshot using the AIâ€™s decision-making ability.

ğŸ“Œ Install Dependencies

pip install langchain google-generativeai undetected-chromedriver selenium beautifulsoup4

ğŸš€ AI Agent-Powered Web Scraping Code

import time
import google.generativeai as genai
import undetected_chromedriver.v2 as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
from langchain.agents import initialize_agent, Tool
from langchain.chat_models import ChatOpenAI
from langchain.tools import Tool
from PIL import Image

# âœ… Set up Gemini 1.5 Pro API Key
GEMINI_API_KEY = "your_gemini_api_key"  # ğŸ”¥ Replace with your Gemini API Key
genai.configure(api_key=GEMINI_API_KEY)

# âœ… Set up LangChain AI Agent
llm = ChatOpenAI(model="gpt-4")

def refine_query_with_gemini(user_query):
    """Uses Gemini 1.5 Pro to refine the search query for better results."""
    model = genai.GenerativeModel("gemini-1.5-pro")
    response = model.generate_content(f"Optimize this search query for better Google search results: {user_query}")
    return response.text.strip()

def get_search_result(query):
    """ğŸ” AI Agent performs Google search in real Chrome"""
    options = uc.ChromeOptions()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")

    driver = uc.Chrome(options=options)  # ğŸš€ Uses Real Chrome
    driver.get("https://www.google.com")

    time.sleep(2)
    search_box = driver.find_element(By.NAME, "q")
    search_box.send_keys(query)
    search_box.send_keys(Keys.RETURN)

    time.sleep(3)

    # AI decides which search result to click
    first_result = driver.find_element(By.CSS_SELECTOR, "h3")
    first_result.click()
    time.sleep(5)

    # AI extracts the current page URL
    page_url = driver.current_url
    driver.quit()
    return page_url

def extract_text_from_page(url):
    """ğŸ“„ AI Extracts text from the page"""
    if not url:
        return ""

    import requests
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    response = requests.get(url, headers=headers)

    soup = BeautifulSoup(response.text, "html.parser")
    paragraphs = soup.find_all("p")
    extracted_text = " ".join([p.get_text() for p in paragraphs if p.get_text()])

    return extracted_text[:3000]  # AI limits text length

def summarize_with_gemini(text):
    """ğŸ’¡ AI Agent uses Gemini to summarize"""
    model = genai.GenerativeModel("gemini-1.5-pro")
    response = model.generate_content(f"Summarize this article concisely:\n\n{text}")
    return response.text.strip()

def take_screenshot(url, output_file="screenshot.png"):
    """ğŸ“¸ AI Agent captures screenshot"""
    if not url:
        return None

    options = uc.ChromeOptions()
    driver = uc.Chrome(options=options)
    
    driver.get(url)
    time.sleep(3)

    driver.save_screenshot(output_file)
    driver.quit()
    
    return output_file

# ğŸ”¥ Define AI Agent Tools
tools = [
    Tool(
        name="Google Search",
        func=get_search_result,
        description="Searches Google for the best information."
    ),
    Tool(
        name="Web Scraper",
        func=extract_text_from_page,
        description="Extracts article text from a given webpage."
    ),
    Tool(
        name="Summarization Agent",
        func=summarize_with_gemini,
        description="Summarizes extracted information using Gemini AI."
    ),
    Tool(
        name="Screenshot Capture",
        func=take_screenshot,
        description="Takes a screenshot of the current webpage."
    )
]

# âœ… Initialize AI Agent
agent = initialize_agent(tools, llm, agent="zero-shot-react-description", verbose=True)

def main():
    """ğŸ’» AI-powered real-time scraping"""
    while True:
        print("\nEnter your search query (or type 'exit' to quit): ")
        query = input().strip()
        
        if query.lower() == "exit":
            print("ğŸ‘‹ Exiting AI scraping agent...")
            break

        # Step 1: AI Refines Query
        refined_query = refine_query_with_gemini(query)
        print(f"ğŸ¯ AI Refined Query: {refined_query}")

        # Step 2: AI searches Google
        result_url = agent.run("Google Search", refined_query)
        print(f"ğŸ”— AI Found Article: {result_url}")

        # Step 3: AI Extracts Article Text
        article_text = agent.run("Web Scraper", result_url)
        print("\nğŸ“œ AI Extracted Text: ", article_text[:500], "...")

        # Step 4: AI Summarizes Content
        summary = agent.run("Summarization Agent", article_text)
        print("\nğŸ’¡ AI Summary:\n", summary)

        # Step 5: AI Takes Screenshot
        screenshot_file = agent.run("Screenshot Capture", result_url)
        if screenshot_file:
            print(f"\nğŸ“¸ AI Screenshot saved: {screenshot_file}")
            img = Image.open(screenshot_file)
            img.show()

        time.sleep(2)

# ğŸš€ Run AI-Powered Web Scraping
if __name__ == "__main__":
    main()

ğŸ”¥ Why This AI Agent Approach is Better

âœ… Uses AI to plan actions dynamically (no predefined steps).
âœ… Integrates LangChain Agents for self-directed web scraping.
âœ… No more rule-based automation â€“ AI decides how to extract information.
âœ… Uses real Chrome browser (no bot detection).
âœ… Summarizes information automatically (no need for manual review).

ğŸš€ Next Steps

Would you like to:
	â€¢	âœ… Train the AI agent to remember past searches?
	â€¢	âœ… Make it extract multiple search results instead of just the first?
	â€¢	âœ… Store the extracted data into a database or an API?

Let me know what features youâ€™d like next! ğŸš€
